{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 복잡도와 모델 정확도\n",
    "- 과대적합 :모델이 너무 복잡하여 학습데이터에 지나치게 최적화되고 일반화하기 어려움\n",
    "- 과소적합 : 모델이 너무 단순하여 학습데이터를 충분히 분석하지 못함\n",
    "- 과대적합과 과소적합의 절충점을 바탕으로 모델의 일반화 성능을 최대화 시킬 수 있는 모델 생성\n",
    "    \n",
    "<img src='img/overfitting2.png' width='300' height='150' align='left'>\n",
    "<img src='img/overfitting.png' width='400' height='200' align='left'>\n",
    "<br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br><br>\n",
    "\n",
    "\n",
    "---\n",
    "### 지도학습 \n",
    "- 결과 값에 대한 라벨이 존재, 입력 데이터를 통해 출력 데이터가 어떤 라벨인지 분류하는 예측 수행\n",
    "\n",
    "- 분류 기준\n",
    "    - 이진 분류 : 결과 값에 대한 라벨이 두 가지 종류(Y/N, Female/Male, Success/Fail 등)    \n",
    "    - 다범주 분류 : n개의 범주로 이루어진 결과 값을 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 의사결정나무(Decision Tree)\n",
    "- 의사결정 규칙을 도표화하여 관심 집단을 몇 개의 소집단으로 분류 / 예측하는 계량적 분석방법\n",
    "- 의사결정나무 모델 학습 방법 \n",
    " - 엔트로피 또는 지니계수를 통해 최적의 특징값을 선정하여 최상위 노드부터 분류 기준으로 적용\n",
    " - 반복적으로 노드를 생성하여 분류\n",
    " - 더 이상 노드를 생성할 수 없거나 지정한 높이(depth)에 도달하면 분류 종료<br>\n",
    "     - node : 분류 기준이 되는 특정 변수와 값\n",
    "     - root node : 첫번째 분류 기준이 되는 최상위 노드\n",
    "     - leaf node : 최상위 노드와 마지막 최종 노드 사이에 존재하는 중간 노드\n",
    "     - leaf : 마지막 최종 노드\n",
    "     - edge : 노드의 분류 결과(T/F)와 다음 노드를 연결\n",
    "     - depth : 최종 노드가 생성될 때 까지의 단계\n",
    "     \n",
    "     \n",
    "- 숫자형 결과를 반환하는 회귀 트리(Regression Tree)와 범주형 결과를 반환하는 분류 트리(Classification Tree)\n",
    "- 직관적인 작동 방식으로 해석력이 아주 좋은 분류 모델로 평가\n",
    "- 여러 개의 변수들에 대해 각각의 중요도를 평가 할 수 있음\n",
    "- 입력 데이터에 대해 범주형 데이터와 숫자형 데이터 모두 적용할 수 있으나 범주형 데이터의 경우 라벨인코딩 적용\n",
    "    - sklearn.preprocessing > OneHotEncoder\n",
    "- 결과 값에 대해 이진 분류와 다범주 분류 모두 가능\n",
    "\n",
    "\n",
    "- 과적합(Over-fitting) 관리 필요\n",
    "    - 학습한 데이터와 다른 새로운 데이터에 대해 일반화하는 성능이 떨어져 과적합 경향이 큰 것이 의사결정나무의 최대 취약점\n",
    "    - depth가 지나치게 크면 과적합 경향이 높음\n",
    "        - clf.set_param(max_depth=n)\n",
    "    - 새로운 node가 생성될 때 사용되는 sample의 개수가 지나치게 작으면 과적합 경향이 높음 \n",
    "        - min_samples_split, min_samples_leaf\n",
    "    - 차원(사용되는 변수)이 너무 많으면 과적합 경향이 높음 \n",
    "        - max_features, PCA\n",
    "    \n",
    "    \n",
    "- 정보획득(Information Gain), 불순도(Criterion) :  Gini Index(기본값), Entropy Index\n",
    "    - 확률변수가 담고 있는 정보(범주)가 얼마나 섞여 있는가를 나타내는 지표\n",
    "    - 분류 후의 순도 증가/불순도 또는 불확실성 감소가 가장 큰 변수를 우선적으로 분류 기준으로 적용\n",
    "    - 최종적으로 0이 되면 균일한 정보(범주)로 이루어진 데이터       \n",
    "    \n",
    "    <img src='img/dtree1.png' width='400' height='150' align='left'>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
